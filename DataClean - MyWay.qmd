---
title: "DataClean - MyWay"
format: html
editor: visual
---

```{r}
require(dplyr)
require(stringr)
require(tidytext)
```

# Predict the President

```{r Data, echo=FALSE}
# Obtain dataset
dir       <- paste0(getwd(), "/Data/") 
ldf       <- list.files(path = dir, pattern = "*.txt")
data      <- data.frame() 

collectData <- function(fileName){
    dat     <- data.frame(readLines(fileName, warn = F))
    strings <- unlist(strsplit(fileName, "_"))
    string  <- gsub(".txt", "", strings[length(strings)])
    dat$date <- dat[1,]
    dat$President <- string
    dat <- dat[-1,]
}

for (i in 1:length(ldf)){
  if (i == 1){
    data <- collectData(paste0(dir ,ldf[i]))
  }
  else {
    data <- rbind(data, collectData(paste0(dir ,ldf[i])))
  }
}
```

```{r Cleaning}
# remove cells that are just a space
# put everything in lower case
# remove any whitespaces
colnames(data) <- c("Text", "President")
data <- data %>% 
  select(President, Text) %>%
  filter(!(Text %in% "")) 

data <- data.frame(lapply(data, str_to_lower))
data <- data.frame(lapply(data, str_trim))

# tokenizing already removes punctuation
aa <- unnest_tokens(tbl = data, input = Text, output = text, token = "words")

############### May have to remove punctuation

# tokenize. Maay not have to tokenize
```
