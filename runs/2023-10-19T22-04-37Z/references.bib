@INPROCEEDINGS{Imbalance,
  author={Mohammed, Roweida and Rawashdeh, Jumanah and Abdullah, Malak},
  booktitle={2020 11th International Conference on Information and Communication Systems (ICICS)}, 
  title={Machine Learning with Oversampling and Undersampling Techniques: Overview Study and Experimental Results}, 
  year={2020},
  volume={},
  number={},
  pages={243-248},
  doi={10.1109/ICICS49469.2020.239556}}

@inproceedings{FunctionWords,
author = {Argamon, Shlomo and Shlomo, Levitan},
year = {2005},
month = {01},
pages = {},
title = {Measuring the Usefulness of Function Words for Authorship Attribution},
journal = {Proceeding of the Joint Conference on Association for Literary and Linguistic Computing/Association Computer Humanities}
}

@Manual{e1071,
    title = {e1071: Misc Functions of the Department of Statistics, Probability
Theory Group (Formerly: E1071), TU Wien},
    author = {David Meyer and Evgenia Dimitriadou and Kurt Hornik and Andreas Weingessel and Friedrich Leisch},
    year = {2023},
    note = {R package version 1.7-13},
    url = {https://CRAN.R-project.org/package=e1071},
  }

@article{LexVsChar,
author = {Stamatatos, Efstathios},
year = {2008},
month = {03},
pages = {790-799},
title = {Author identification: Using text sampling to handle the class imbalance problem},
volume = {44},
journal = {Information Processing & Management},
doi = {10.1016/j.ipm.2007.05.012}
}

@book{TextMining,
author = {Silge, Julia and Robinson, David},
title = {Text Mining with R: A Tidy Approach},
year = {2017},
isbn = {1491981652},
publisher = {O'Reilly Media, Inc.},
edition = {1st},
abstract = {Much of the data available today is unstructured and text-heavy, making it challenging for analysts to apply their usual data wrangling and visualization tools. With this practical book, youll explore text-mining techniques with tidytext, a package that authors Julia Silge and David Robinson developed using the tidy principles behind R packages like ggraph and dplyr. Youll learn how tidytext and other tidy tools in R can make text analysis easier and more effective. The authors demonstrate how treating text as data frames enables you to manipulate, summarize, and visualize characteristics of text. Youll also learn how to integrate natural language processing (NLP) into effective workflows. Practical code examples and data explorations will help you generate real insights from literature, news, and social media. Learn how to apply the tidy text format to NLPUse sentiment analysis to mine the emotional content of text Identify a documents most important terms with frequency measurements Explore relationships and connections between words with the ggraph and widyr packages Convert back and forth between Rs tidy and non-tidy text formatsUse topic modeling to classify document collections into natural groups Examine case studies that compare Twitter archives, dig into NASA metadata, and analyze thousands of Usenet messages}
}

@Article{unnest_tokens,
  title = {Fast, Consistent Tokenization of Natural Language Text},
  author = {Lincoln A. Mullen and Kenneth Benoit and Os Keyes and Dmitry Selivanov and Jeffrey Arnold},
  journal = {Journal of Open Source Software},
  year = {2018},
  volume = {3},
  issue = {23},
  pages = {655},
  url = {https://doi.org/10.21105/joss.00655},
  doi = {10.21105/joss.00655},
}

@Manual{textclean,
    title = {textclean: Text Cleaning Tools},
    author = {Tyler W. Rinker},
    address = {Buffalo, New York},
    note = {version 0.9.3},
    year = {2018},
    url = {https://github.com/trinker/textclean},
}
@article{Hastie,
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2001},
  month = {01},
  pages = {},
  title = {The Elements Of Statistical Learning},
  volume = {1},
  journal = {Aug, Springer},
  doi = {10.1007/978-0-387-21606-5_7}
  }


@misc{Et,
  author = {Pienaar, E.},
  title = {Neural Networks},
  institution = {University of Cape Town},
  year = {2023}}
}

@misc{Et2,
  author = {Pienaar, E.},
  title = {Support Vector Machines},
  institution = {University of Cape Town},
  year = {2023}}
}


@inproceedings{Jurafsky2000SpeechAL,
  title={Speech and language processing - an introduction to natural language processing, computational linguistics, and speech recognition},
  author={Dan Jurafsky and James H. Martin},
  booktitle={Prentice Hall series in artificial intelligence},
  year={2023},
  url={https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf}
}

@article{Punc,
author = {Zheng, Rong and Li, Jiexun and Chen, Hsinchun and Huang, Zan},
title = {A framework for authorship identification of online messages: Writing-style features and classification techniques},
journal = {Journal of the American Society for Information Science and Technology},
volume = {57},
number = {3},
pages = {378-393},
doi = {https://doi.org/10.1002/asi.20316},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.20316},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.20316},
abstract = {Abstract With the rapid proliferation of Internet technologies and applications, misuse of online messages for inappropriate or illegal purposes has become a major concern for society. The anonymous nature of online-message distribution makes identity tracing a critical problem. We developed a framework for authorship identification of online messages to address the identity-tracing problem. In this framework, four types of writing-style features (lexical, syntactic, structural, and content-specific features) are extracted and inductive learning algorithms are used to build feature-based classification models to identify authorship of online messages. To examine this framework, we conducted experiments on English and Chinese online-newsgroup messages. We compared the discriminating power of the four types of features and of three classification techniques: decision trees, backpropagation neural networks, and support vector machines. The experimental results showed that the proposed approach was able to identify authors of online messages with satisfactory accuracy of 70 to 95\%. All four types of message features contributed to discriminating authors of online messages. Support vector machines outperformed the other two classification techniques in our experiments. The high performance we achieved for both the English and Chinese datasets showed the potential of this approach in a multiple-language context.},
year = {2006}
}


@inproceedings{Bergsma,
author = {Bergsma, Shane and Post, Matt and Yarowsky, David},
year = {2012},
month = {06},
pages = {327-337},
title = {Stylometric analysis of scientific articles}
}

@article{Stylometry,
author = {Stamatatos, Efstathios},
title = {A survey of modern authorship attribution methods},
journal = {Journal of the American Society for Information Science and Technology},
volume = {60},
number = {3},
pages = {538-556},
doi = {https://doi.org/10.1002/asi.21001},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.21001},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/asi.21001},
abstract = {Abstract Authorship attribution supported by statistical or computational methods has a long history starting from the 19th century and is marked by the seminal study of Mosteller and Wallace (1964) on the authorship of the disputed “Federalist Papers.” During the last decade, this scientific field has been developed substantially, taking advantage of research advances in areas such as machine learning, information retrieval, and natural language processing. The plethora of available electronic texts (e.g., e-mail messages, online forum messages, blogs, source code, etc.) indicates a wide variety of applications of this technology, provided it is able to handle short and noisy text from multiple candidate authors. In this article, a survey of recent advances of the automated approaches to attributing authorship is presented, examining their characteristics for both text representation and text classification. The focus of this survey is on computational requirements and settings rather than on linguistic or literary issues. We also discuss evaluation methodologies and criteria for authorship attribution studies and list open questions that will attract future work in this area.},
year = {2009}
}

@article{Tiffani2020OptimizationON,
  title={Optimization of Na{\"i}ve Bayes Classifier By Implemented Unigram, Bigram, Trigram for Sentiment Analysis of Hotel Review},
  author={Ilham Esa Tiffani},
  journal={Journal of Soft Computing Exploration},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:228958822}
}

@Article{Caret,
    title = {Building Predictive Models in R Using the caret Package},
    volume = {28},
    url = {https://www.jstatsoft.org/index.php/jss/article/view/v028i05},
    doi = {10.18637/jss.v028.i05},
    number = {5},
    journal = {Journal of Statistical Software},
    author = {{Kuhn} and {Max}},
    year = {2008},
    pages = {1–26},
  }

@Article{WordFreq,
AUTHOR = {Škorić, Mihailo and Stanković, Ranka and Ikonić Nešić, Milica and Byszuk, Joanna and Eder, Maciej},
TITLE = {Parallel Stylometric Document Embeddings with Deep Learning Based Language Models in Literary Authorship Attribution},
JOURNAL = {Mathematics},
VOLUME = {10},
YEAR = {2022},
NUMBER = {5},
ARTICLE-NUMBER = {838},
URL = {https://www.mdpi.com/2227-7390/10/5/838},
ISSN = {2227-7390},
ABSTRACT = {This paper explores the effectiveness of parallel stylometric document embeddings in solving the authorship attribution task by testing a novel approach on literary texts in 7 different languages, totaling in 7051 unique 10,000-token chunks from 700 PoS and lemma annotated documents. We used these documents to produce four document embedding models using Stylo R package (word-based, lemma-based, PoS-trigrams-based, and PoS-mask-based) and one document embedding model using mBERT for each of the seven languages. We created further derivations of these embeddings in the form of average, product, minimum, maximum, and l2 norm of these document embedding matrices and tested them both including and excluding the mBERT-based document embeddings for each language. Finally, we trained several perceptrons on the portions of the dataset in order to procure adequate weights for a weighted combination approach. We tested standalone (two baselines) and composite embeddings for classification accuracy, precision, recall, weighted-average, and macro-averaged F1-score, compared them with one another and have found that for each language most of our composition methods outperform the baselines (with a couple of methods outperforming all baselines for all languages), with or without mBERT inputs, which are found to have no significant positive impact on the results of our methods.},
DOI = {10.3390/math10050838}
}

@inproceedings{Ngrams,
author = {Coyotl-Morales, Rosa and Villaseñor-Pineda, Luis and Montes, Manuel and Rosso, Paolo},
year = {2006},
month = {11},
pages = {844-853},
title = {Authorship Attribution Using Word Sequences},
volume = {4225},
isbn = {978-3-540-46556-0},
doi = {10.1007/11892755_87}
}

@online{Durbach2023,
  author = {Durbach, Ian},
  title = {Bag-of-words & tf-idf models},
  year = {2023},
  howpublished = {HTML file},
  url = {05-textmining-03.html},
  institution = {University of Cape Town},
  note = {Course: Data Science for Industry}
}

