---
title: "Supplementary 2"
author: "Edward Baleni"
format: html
editor: visual
---


```{r Packages}
require(dplyr)
require(stringr)
require(tidytext)
require(ggplot2)
require(tidyr)
require(forcats)
require(textstem)
require(qdap)
```

```{r Data}
set.seed(2023)
sys.source("sona-first-steps.R" , envir = knitr::knit_global())
sona <- as_tibble(sona)
```

```{r Cleaning Data}
sentences <- sona %>%
  unnest_sentences(speech, speech) #%>%
  #mutate(ids = row_number())

clean <- function(x){
  x <- gsub("\\d+", "", x)
  # remove contractions
  x <- gsub("/'s", "", x)
  # remove special characters
  x <- gsub("[^[:alnum:] ]", "", x)
  # lemmatization
  x <- lemmatize_strings(x)
  # remove single characters
  x <- gsub("\\s.\\s", " ", x)
}

# remove numbers
sentences$speech <- unlist(lapply(sentences$speech, clean))
```

```{r}
data <- sentences %>%
  filter(!president %in% c("deKlerk", "Motlanthe"))
data$president <- as.factor(data$president)
```

```{r Bag of Words}
# Need to remove first sentence for each president, to analyse count well
# Since first sentence is similar for each president
hold <- c()
for (i in unique(data$filename)){
  hold <- c(hold, which( data$filename %in% i)[1])
}
data_count <- data[-hold,]
```


```{r Bag of Words}
uni <- data_count %>%
  unnest_tokens(token, speech) %>%
  filter(!token %in% stop_words$word) %>%
  count(president, token)

uni %>%
  group_by(president) %>%
  summarise(total = sum(n))

uni_tf_idf <- uni %>%
  bind_tf_idf(token, president, n) %>%
  mutate( ids = row_number())

uni_tf_idf %>%
  group_by(president) %>%
  slice_max(n, n= 15)%>%
  ungroup() %>%
  mutate(token = reorder(token, n, decreasing = F)) %>%
  ggplot(aes(n, token, fill = president)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~president, ncol = 2, scales = "free") +
  labs(x = "Count", y = NULL)
```

```{r}
data_count <- data_count %>%
  mutate(ids = row_number())

tidy_tweets <- data_count %>%
  unnest_tokens(token, speech) %>%
  filter(!token %in% stop_words$word)
  
word_bag <- tidy_tweets %>%
  group_by(token) %>%
  count() %>%
  ungroup() %>%
  top_n(200, wt = n) %>%
  select(-n)

tweets_tdf <- tidy_tweets %>%
  inner_join(word_bag) %>%
  group_by(ids,token) %>%
  count() %>%  
  group_by(ids) %>%
  mutate(total = sum(n)) %>%
  ungroup()


bag_of_words <- tweets_tdf %>% 
  select(ids, token, n) %>% 
  pivot_wider(names_from = token, values_from = n, values_fill = 0) 



words_tdf <- uni_tf_idf %>%
  inner_join(word_bag)

bag_of_words <- words_tdf %>% 
  select(ids, token, n) %>% 
  pivot_wider(names_from = token, values_from = n, values_fill = 0)


bag_of_words <- uni_tf_idf %>%
  select(ids, president) %>%
  rename (Response_President = president) %>%
  right_join(bag_of_words, join_by("ids")) %>%
  select(ids, Response_President, everything()) 
```

```{r}
set.seed(321)
training_ids <- bag_of_words %>% 
  group_by(Response_President) %>% 
  slice_sample(prop = 0.7) %>% 
  ungroup() %>%
  select(ids)

training_tweets <- bag_of_words %>% 
  right_join(training_ids, by = 'ids') %>%
  select(-ids)

test_tweets <- bag_of_words %>% 
  anti_join(training_ids, by = 'ids') %>%
  select(-ids)
```

```{r}
library(e1071)
data_classifier <- naiveBayes(training_tweets[,-1], training_tweets[,1])

#plot(mod)
p1 <- predict(data_classifier, test_tweets[,-1])

tt <- table((p1), (unlist(test_tweets[,1])))

1 - sum(diag(tt))/ sum(tt)
```














```{r}
data_count <- data %>%
  mutate(ids = row_number())

tidy_ <- data_count %>%
  unnest_tokens(token, speech) %>%
  filter(!token %in% stop_words$word)

tweets_tdf <-  tidy_ %>%
  group_by(ids, token) %>%
  count() %>%
  group_by(ids) %>%
  mutate(total = sum(n)) %>%
  ungroup()

tweets_tdf <- tweets_tdf %>%
  bind_tf_idf(token, ids, n)

# # Calculate the mean TF-IDF score for each term across all presidents
# term_mean_tfidf <- tweets_tdf %>%
#   group_by(token) %>%
#   summarize(mean_tfidf = mean(tf_idf, na.rm = TRUE)) %>%
#   arrange(desc(mean_tfidf))
# 
# # Select the top 200 terms
# top_terms <- term_mean_tfidf$token[1:200]
# 
# # Filter your dataframe to keep only these top terms
# tweets_tdf_top200 <- tweets_tdf %>%
#   filter(token %in% top_terms)

# 
# 
# # Maybe pick out the top 200 on tf_idf alone
# word_bag2 <- tweets_tdf %>%
#   top_n(n = 200, wt = n)
# #
# 
#tweets_tdf <- tweets_tdf %>%
#  semi_join(word_bag)

tfidf <- tweets_tdf %>% 
  select(ids, token, tf_idf) %>%  # note the change, using tf-idf
  pivot_wider(names_from = token, values_from = tf_idf, values_fill = 0)


tfidf <- uni_tf_idf %>%
  select(ids, president) %>%
  rename (Response_President = president) %>%
  right_join(tfidf, join_by("ids")) %>%
  select(ids, Response_President, everything()) 


# #Converting the frequency of word to count
# convert_counts <- function(x) {
#         x <- ifelse(x > 0, 1, 0)
#         x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
#         return(x)
# }
# 
# #Appending count function to Train and Test Dataset
# data_train <- apply(tfidf[,-c(1,2)], MARGIN = 2, convert_counts)
# 
# data_train <- model.matrix(~. -1, data=data.frame(data_train))
# 
# 
# tfidf <-  data.frame(tfidf[,c(1,2)], data_train)
```


```{r}
set.seed(321) 
training_ids <- tfidf %>% 
  group_by(Response_President) %>% 
  slice_sample(prop = 0.7) %>% 
  ungroup() %>%
  select(ids)

training_tweets <- tfidf %>% 
  right_join(training_ids, by = 'ids') %>%
  select(-ids)

test_tweets <- tfidf %>% 
  anti_join(training_ids, by = 'ids') %>%
  select(-ids)
```

```{r Naive Bayes Classifier}
library(e1071)
data_classifier <- naiveBayes(training_tweets[,-1], training_tweets[,1])

#plot(mod)
p1 <- predict(data_classifier, test_tweets[,-1])

tt <- table((p1), (unlist(test_tweets[,1])))

1 - sum(diag(tt))/ sum(tt)
```

```{r Support Vector Machine}
# This works for a a reasonably sized word bag
classifier = svm(training_tweets[,-1], training_tweets[,1], type = "C-classification", scale = F)
  #svm(formula = Response_President ~ ., 
  #               data = training_tweets, 
  #               type = 'C-classification', 
  #               kernel = 'linear') 

p1 <- predict(classifier, test_tweets[,-1])

tt <- table((p1), (unlist(test_tweets[,1])))

1 - sum(diag(tt))/ sum(tt)
```

```{r FFNN}

```



